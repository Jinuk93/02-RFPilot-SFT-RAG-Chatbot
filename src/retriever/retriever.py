from langchain_chroma import Chroma
from langchain_openai.embeddings import OpenAIEmbeddings
from langsmith import traceable
import time
import os
from rank_bm25 import BM25Okapi
import numpy as np
from sentence_transformers import CrossEncoder

from src.utils.config import RAGConfig


class RAGRetriever:
    """RAG ê²€ìƒ‰ ì‹œìŠ¤í…œ (Hybrid Search + Re-ranker)"""

    def __init__(self, config: RAGConfig = None):
        self.config = config or RAGConfig()
        self.vectorstore = None
        self.embeddings = None

        self._initialize_embeddings()
        self._create_vectorstore()
        self._initialize_bm25()
        self._initialize_reranker()

    def _initialize_embeddings(self):
        """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        os.environ["OPENAI_API_KEY"] = self.config.OPENAI_API_KEY

        self.embeddings = OpenAIEmbeddings(
            model=self.config.EMBEDDING_MODEL_NAME
        )

    def _create_vectorstore(self):
        """ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ"""
        self.vectorstore = Chroma(
            embedding_function=self.embeddings,
            persist_directory=self.config.DB_DIRECTORY,
            collection_name=self.config.COLLECTION_NAME
        )

    def _initialize_bm25(self):
        """BM25 ì¸ë±ìŠ¤ ìƒì„±"""
        all_docs = self.vectorstore.get()
        
        self.doc_texts = all_docs['documents']
        self.doc_ids = all_docs['ids']
        self.doc_metadatas = all_docs['metadatas']
        
        self.content_to_id = {text: doc_id for text, doc_id in zip(self.doc_texts, self.doc_ids)}
        
        tokenized_docs = [doc.split() for doc in self.doc_texts]
        self.bm25 = BM25Okapi(tokenized_docs)
        
        print(f"âœ… BM25 ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {len(self.doc_texts)}ê°œ ë¬¸ì„œ")

    def _initialize_reranker(self):
        """Re-ranker ì´ˆê¸°í™”"""
        self.reranker = CrossEncoder('BAAI/bge-reranker-base')
        print("âœ… Re-ranker ì´ˆê¸°í™” ì™„ë£Œ (bge-reranker-base)")

    @staticmethod
    def _min_max_normalize(scores):
        """0~1 ë²”ìœ„ë¡œ ì •ê·œí™”"""
        scores = np.array(scores)
        min_score = scores.min()
        max_score = scores.max()
        
        if max_score == min_score:
            return np.full_like(scores, 0.5, dtype=float)
        
        return (scores - min_score) / (max_score - min_score)

    def _find_doc_id_by_content(self, content):
        """ë¬¸ì„œ contentë¡œ ID ì°¾ê¸°"""
        return self.content_to_id.get(content, None)

    def _rerank(self, query, documents, top_k):
        """
        ê²€ìƒ‰ ê²°ê³¼ ì¬ì •ë ¬
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            documents: hybrid_search ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            top_k: ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
        
        Returns:
            ì¬ì •ë ¬ëœ ìƒìœ„ kê°œ ë¬¸ì„œ
        """
        if len(documents) == 0:
            return []
        
        # 1. (query, document) ìŒ ìƒì„±
        pairs = [[query, doc['content']] for doc in documents]
        
        # 2. CrossEncoderë¡œ ì ìˆ˜ ê³„ì‚°
        scores = self.reranker.predict(pairs)
        
        # 3. ì ìˆ˜ë¥¼ ë¬¸ì„œì— ì¶”ê°€
        for i, doc in enumerate(documents):
            doc['rerank_score'] = float(scores[i])
        
        # 4. ì •ë ¬ ë° ë°˜í™˜
        sorted_docs = sorted(documents, 
                            key=lambda x: x['rerank_score'], 
                            reverse=True)
        
        return sorted_docs[:top_k]

    @traceable(
        name="RAG_Hybrid_Search",
        metadata={"component": "retriever", "version": "2.0"}
    )
    def hybrid_search(self, query, top_k=None, alpha=0.5):
        """
        Hybrid Search: BM25 + ì„ë² ë”© ê²°í•©
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            alpha: ì„ë² ë”© ê°€ì¤‘ì¹˜ (0~1)
        """
        start_time = time.time()
        
        if top_k is None:
            top_k = self.config.DEFAULT_TOP_K
        
        # 1. BM25 ê²€ìƒ‰
        tokenized_query = query.split()
        bm25_scores = self.bm25.get_scores(tokenized_query)
        bm25_normalized = self._min_max_normalize(bm25_scores)
        
        # 2. ì„ë² ë”© ê²€ìƒ‰
        embedding_results = self.vectorstore.similarity_search_with_score(
            query, k=min(top_k * 3, len(self.doc_texts))
        )
        
        # 3. ì„ë² ë”© ì ìˆ˜ ì •ê·œí™”
        embedding_scores_raw = {}
        for doc, distance in embedding_results:
            doc_id = self._find_doc_id_by_content(doc.page_content)
            if doc_id:
                embedding_scores_raw[doc_id] = 1 / (1 + distance)
        
        if embedding_scores_raw:
            embed_values = np.array(list(embedding_scores_raw.values()))
            embed_normalized = self._min_max_normalize(embed_values)
            embedding_scores = dict(zip(embedding_scores_raw.keys(), embed_normalized))
        else:
            embedding_scores = {}
        
        # 4. í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
        hybrid_scores = {}
        for i, doc_id in enumerate(self.doc_ids):
            bm25_score = bm25_normalized[i]
            embed_score = embedding_scores.get(doc_id, 0)
            hybrid_scores[doc_id] = (1 - alpha) * bm25_score + alpha * embed_score
        
        # 5. ì •ë ¬ ë° ìƒìœ„ kê°œ ì„ íƒ
        sorted_ids = sorted(hybrid_scores.keys(), 
                           key=lambda x: hybrid_scores[x], 
                           reverse=True)
        top_ids = sorted_ids[:top_k]
        
        # 6. ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = []
        for doc_id in top_ids:
            idx = self.doc_ids.index(doc_id)
            formatted_results.append({
                'content': self.doc_texts[idx],
                'metadata': self.doc_metadatas[idx],
                'hybrid_score': hybrid_scores[doc_id],
                'bm25_score': float(bm25_normalized[idx]),
                'embed_score': embedding_scores.get(doc_id, 0),
                'filename': self.doc_metadatas[idx].get('íŒŒì¼ëª…', 'N/A'),
                'organization': self.doc_metadatas[idx].get('ë°œì£¼ ê¸°ê´€', 'N/A')
            })
        
        end_time = time.time()
        print(f"ğŸ” Hybrid ê²€ìƒ‰ ì™„ë£Œ: {len(formatted_results)}ê°œ (alpha={alpha}, {end_time-start_time:.3f}ì´ˆ)")
        return formatted_results

    @traceable(
        name="RAG_Hybrid_Search_Rerank",
        metadata={"component": "retriever", "version": "3.0"}
    )
    def hybrid_search_with_rerank(self, query, top_k=None, alpha=0.5, rerank_candidates=None):
        """
        Hybrid Search + Re-ranking
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            alpha: BM25/ì„ë² ë”© ê°€ì¤‘ì¹˜
            rerank_candidates: Re-rankí•  í›„ë³´ ìˆ˜ (Noneì´ë©´ top_k * 3)
        """
        start_time = time.time()
        
        if top_k is None:
            top_k = self.config.DEFAULT_TOP_K
        
        if rerank_candidates is None:
            rerank_candidates = top_k * 3
        
        # 1. Hybrid Searchë¡œ í›„ë³´ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        candidates = self.hybrid_search(query, top_k=rerank_candidates, alpha=alpha)
        
        # 2. Re-ranking
        if len(candidates) > 0:
            results = self._rerank(query, candidates, top_k)
        else:
            results = []
        
        end_time = time.time()
        print(f"ğŸ”„ Re-ranking ì™„ë£Œ: {len(candidates)}ê°œ â†’ {len(results)}ê°œ ({end_time-start_time:.3f}ì´ˆ)")
        
        return results

    def search_with_mode(self, query, top_k=None, mode="hybrid_rerank", alpha=0.5):
        """ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ"""
        if mode == "embedding":
            return self.search(query, top_k)
        elif mode == "bm25":
            return self.hybrid_search(query, top_k, alpha=0.0)
        elif mode == "hybrid":
            return self.hybrid_search(query, top_k, alpha=alpha)
        elif mode == "hybrid_rerank":
            return self.hybrid_search_with_rerank(query, top_k, alpha)
        else:
            raise ValueError(f"Unknown mode: {mode}")

    @traceable(
        name="RAG_Retriever_Search",
        metadata={"component": "retriever", "version": "1.0"}
    )
    def search(self, query: str, top_k: int = None, filter_metadata: dict = None):
        """
        ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ (ì„ë² ë”© ê¸°ë°˜)
        """
        start_time = time.time()
        if top_k is None:
            top_k = self.config.DEFAULT_TOP_K

        if filter_metadata:
            results = self.vectorstore.similarity_search_with_score(
                query, k=top_k, filter=filter_metadata
            )
        else:
            results = self.vectorstore.similarity_search_with_score(
                query, k=top_k
            )

        formatted_results = []
        for doc, score in results:
            formatted_results.append({
                'content': doc.page_content,
                'metadata': doc.metadata,
                'distance': score,
                'relevance_score': 1 - score,
                'filename': doc.metadata.get('íŒŒì¼ëª…', 'N/A'),
                'organization': doc.metadata.get('ë°œì£¼ ê¸°ê´€', 'N/A')
            })

        end_time = time.time()
        print(f"ğŸ” ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ({end_time-start_time:.3f}ì´ˆ)")
        return formatted_results

    def search_with_rerank(self, query, top_k=None, rerank_candidates=None):
        """
        ì„ë² ë”© ê²€ìƒ‰ + Re-ranking
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            rerank_candidates: Re-rankí•  í›„ë³´ ìˆ˜
        
        Returns:
            ì¬ì •ë ¬ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        start_time = time.time()
        
        if top_k is None:
            top_k = self.config.DEFAULT_TOP_K
        
        if rerank_candidates is None:
            rerank_candidates = top_k * 3
        
        # 1. ì„ë² ë”© ê²€ìƒ‰ìœ¼ë¡œ í›„ë³´ ê°€ì ¸ì˜¤ê¸°
        candidates = self.search(query, top_k=rerank_candidates)
        
        # 2. Re-ranking
        if len(candidates) > 0:
            results = self._rerank(query, candidates, top_k)
        else:
            results = []
        
        end_time = time.time()
        print(f"ğŸ”„ Embedding + Re-ranking ì™„ë£Œ: {len(candidates)}ê°œ â†’ {len(results)}ê°œ ({end_time-start_time:.3f}ì´ˆ)")
        
        return results

    def search_by_organization(self, query: str, organization: str, top_k: int = None):
        """íŠ¹ì • ë°œì£¼ê¸°ê´€ë§Œ ê²€ìƒ‰"""
        return self.search(
            query, top_k=top_k, filter_metadata={'ë°œì£¼ ê¸°ê´€': organization}
        )

    def get_retriever(self):
        """LangChain ì²´ì¸ìš© Retriever ë°˜í™˜"""
        return self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": self.config.DEFAULT_TOP_K}
        )