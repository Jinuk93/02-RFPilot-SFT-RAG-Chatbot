# ===== experiment_tracker.py =====
"""
RAG ê²€ìƒ‰ ì‹œìŠ¤í…œ ì‹¤í—˜ ì¶”ì  ë° ë¹„êµ ë„êµ¬

ê¸°ëŠ¥:
1. ì‹¤í—˜ ê²°ê³¼ ìë™ ì €ì¥
2. ì´ì „ ì‹¤í—˜ê³¼ ë¹„êµ
3. ì„±ëŠ¥ ì°¨íŠ¸ ìƒì„±
4. ìµœì  ì„¤ì • ì¶”ì²œ
"""

import json
import pandas as pd
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # ì„œë²„ í™˜ê²½ ëŒ€ì‘


class ExperimentTracker:
    """ì‹¤í—˜ ì¶”ì  ë° ë¹„êµ í´ë˜ìŠ¤"""
    
    def __init__(self, log_dir: str = "src/evaluation/results/experiments"):
        """
        Args:
            log_dir: ì‹¤í—˜ ë¡œê·¸ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        self.log_file = self.log_dir / "experiments_log.json"
        self.summary_file = self.log_dir / "experiments_summary.csv"
        
        # ë¡œê·¸ íŒŒì¼ ì´ˆê¸°í™”
        if not self.log_file.exists():
            self._save_log([])
    
    
    # === 1. ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ===
    
    def log_experiment(
        self,
        experiment_name: str,
        config: Dict[str, Any],
        metrics: Dict[str, float],
        langsmith_url: Optional[str] = None,
        notes: str = ""
    ) -> None:
        """
        ì‹¤í—˜ ê²°ê³¼ ì €ì¥
        
        Args:
            experiment_name: ì‹¤í—˜ ì´ë¦„ (ì˜ˆ: "baseline", "embedding-small")
            config: ì„¤ì • ì •ë³´ (ì„ë² ë”© ëª¨ë¸, Top-K ë“±)
            metrics: í‰ê°€ ì§€í‘œ (precision, recall ë“±)
            langsmith_url: LangSmith ê²°ê³¼ URL
            notes: ì¶”ê°€ ë©”ëª¨
        """
        # ì‹¤í—˜ ë°ì´í„° êµ¬ì„±
        experiment_data = {
            "timestamp": datetime.now().isoformat(),
            "experiment_name": experiment_name,
            "config": config,
            "metrics": metrics,
            "langsmith_url": langsmith_url,
            "notes": notes
        }
        
        # ê¸°ì¡´ ë¡œê·¸ ë¡œë“œ
        logs = self._load_log()
        
        # ìƒˆ ì‹¤í—˜ ì¶”ê°€
        logs.append(experiment_data)
        
        # ì €ì¥
        self._save_log(logs)
        self._update_summary()
        
        print(f"âœ… ì‹¤í—˜ '{experiment_name}' ì €ì¥ ì™„ë£Œ")
        print(f"   Precision: {metrics.get('precision', 0):.4f}")
        print(f"   Recall: {metrics.get('recall', 0):.4f}")
    
    
    # === 2. ì‹¤í—˜ ë¹„êµ ===
    
    def compare_experiments(
        self,
        experiment_names: Optional[List[str]] = None,
        top_n: int = 5
    ) -> pd.DataFrame:
        """
        ì‹¤í—˜ ê²°ê³¼ ë¹„êµ
        
        Args:
            experiment_names: ë¹„êµí•  ì‹¤í—˜ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ìµœê·¼ ì‹¤í—˜)
            top_n: experiment_namesê°€ Noneì¼ ë•Œ ìµœê·¼ ëª‡ ê°œ ë¹„êµí• ì§€
            
        Returns:
            ë¹„êµ ê²°ê³¼ DataFrame
        """
        logs = self._load_log()
        
        if not logs:
            print("âš ï¸ ì €ì¥ëœ ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame()
        
        # ë¹„êµí•  ì‹¤í—˜ ì„ íƒ
        if experiment_names is None:
            # ìµœê·¼ Nê°œ
            selected_logs = logs[-top_n:]
        else:
            # ì§€ì •ëœ ì‹¤í—˜ë“¤
            selected_logs = [
                log for log in logs 
                if log['experiment_name'] in experiment_names
            ]
        
        if not selected_logs:
            print("âš ï¸ ë¹„êµí•  ì‹¤í—˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame()
        
        # DataFrame ìƒì„±
        comparison_data = []
        for log in selected_logs:
            row = {
                "ì‹¤í—˜ëª…": log['experiment_name'],
                "ë‚ ì§œ": log['timestamp'][:10],
                "ì„ë² ë”©": log['config'].get('embedding_model', 'N/A'),
                "Top-K": log['config'].get('top_k', 'N/A'),
                "Precision": log['metrics'].get('precision', 0),
                "Recall": log['metrics'].get('recall', 0),
                "F1": self._calculate_f1(
                    log['metrics'].get('precision', 0),
                    log['metrics'].get('recall', 0)
                ),
                "ê²€ìƒ‰ì‹œê°„(ì´ˆ)": log['metrics'].get('avg_time', 0)
            }
            comparison_data.append(row)
        
        df = pd.DataFrame(comparison_data)
        
        # ì¶œë ¥
        print("\n" + "="*80)
        print("ğŸ“Š ì‹¤í—˜ ë¹„êµ ê²°ê³¼")
        print("="*80)
        print(df.to_string(index=False))
        print("="*80)
        
        return df
    
    
    def show_improvement(self, baseline_name: str, current_name: str) -> None:
        """
        Baseline ëŒ€ë¹„ ê°œì„  íš¨ê³¼ ì¶œë ¥
        
        Args:
            baseline_name: ê¸°ì¤€ ì‹¤í—˜ ì´ë¦„
            current_name: ë¹„êµí•  ì‹¤í—˜ ì´ë¦„
        """
        logs = self._load_log()
        
        # ì‹¤í—˜ ì°¾ê¸°
        baseline = next((log for log in logs if log['experiment_name'] == baseline_name), None)
        current = next((log for log in logs if log['experiment_name'] == current_name), None)
        
        if not baseline or not current:
            print("âš ï¸ ì‹¤í—˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # ê°œì„ ìœ¨ ê³„ì‚°
        baseline_precision = baseline['metrics'].get('precision', 0)
        baseline_recall = baseline['metrics'].get('recall', 0)
        
        current_precision = current['metrics'].get('precision', 0)
        current_recall = current['metrics'].get('recall', 0)
        
        precision_improvement = (current_precision - baseline_precision) / baseline_precision * 100 if baseline_precision > 0 else 0
        recall_improvement = (current_recall - baseline_recall) / baseline_recall * 100 if baseline_recall > 0 else 0
        
        # ì¶œë ¥
        print("\n" + "="*80)
        print(f"ğŸ“ˆ ê°œì„  íš¨ê³¼: {baseline_name} â†’ {current_name}")
        print("="*80)
        print(f"\nPrecision:")
        print(f"  {baseline_name}: {baseline_precision:.4f}")
        print(f"  {current_name}: {current_precision:.4f}")
        print(f"  ê°œì„ ìœ¨: {precision_improvement:+.2f}% {'âœ…' if precision_improvement > 0 else 'âŒ'}")
        
        print(f"\nRecall:")
        print(f"  {baseline_name}: {baseline_recall:.4f}")
        print(f"  {current_name}: {current_recall:.4f}")
        print(f"  ê°œì„ ìœ¨: {recall_improvement:+.2f}% {'âœ…' if recall_improvement > 0 else 'âŒ'}")
        
        print("\n" + "="*80)
    
    
    # === 3. ì‹œê°í™” ===
    
    def plot_metrics(
        self,
        experiment_names: Optional[List[str]] = None,
        save_path: Optional[str] = None
    ) -> None:
        """
        ì‹¤í—˜ ê²°ê³¼ ì°¨íŠ¸ ìƒì„±
        
        Args:
            experiment_names: ì°¨íŠ¸ì— í¬í•¨í•  ì‹¤í—˜ (Noneì´ë©´ ì „ì²´)
            save_path: ì°¨íŠ¸ ì €ì¥ ê²½ë¡œ (Noneì´ë©´ í™”ë©´ ì¶œë ¥)
        """
        logs = self._load_log()
        
        if not logs:
            print("âš ï¸ ì €ì¥ëœ ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # ì‹¤í—˜ ì„ íƒ
        if experiment_names is not None:
            logs = [log for log in logs if log['experiment_name'] in experiment_names]
        
        if not logs:
            print("âš ï¸ ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # ë°ì´í„° ì¤€ë¹„
        names = [log['experiment_name'] for log in logs]
        precisions = [log['metrics'].get('precision', 0) for log in logs]
        recalls = [log['metrics'].get('recall', 0) for log in logs]
        
        # ì°¨íŠ¸ ìƒì„±
        fig, ax = plt.subplots(figsize=(12, 6))
        
        x = range(len(names))
        width = 0.35
        
        ax.bar([i - width/2 for i in x], precisions, width, label='Precision', alpha=0.8)
        ax.bar([i + width/2 for i in x], recalls, width, label='Recall', alpha=0.8)
        
        ax.set_xlabel('ì‹¤í—˜')
        ax.set_ylabel('ì ìˆ˜')
        ax.set_title('ì‹¤í—˜ë³„ ì„±ëŠ¥ ë¹„êµ')
        ax.set_xticks(x)
        ax.set_xticklabels(names, rotation=45, ha='right')
        ax.legend()
        ax.grid(axis='y', alpha=0.3)
        
        plt.tight_layout()
        
        # ì €ì¥ ë˜ëŠ” ì¶œë ¥
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… ì°¨íŠ¸ ì €ì¥: {save_path}")
        else:
            default_path = self.log_dir / "comparison_chart.png"
            plt.savefig(default_path, dpi=300, bbox_inches='tight')
            print(f"âœ… ì°¨íŠ¸ ì €ì¥: {default_path}")
        
        plt.close()
    
    
    # === 4. ìµœì  ì„¤ì • ì¶”ì²œ ===
    
    def recommend_best(self, metric: str = "f1") -> Dict[str, Any]:
        """
        ìµœì  ì„¤ì • ì¶”ì²œ
        
        Args:
            metric: ê¸°ì¤€ ì§€í‘œ ("precision", "recall", "f1")
            
        Returns:
            ìµœì  ì‹¤í—˜ ì •ë³´
        """
        logs = self._load_log()
        
        if not logs:
            print("âš ï¸ ì €ì¥ëœ ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤")
            return {}
        
        # F1 ì ìˆ˜ ê³„ì‚°
        for log in logs:
            if 'f1' not in log['metrics']:
                p = log['metrics'].get('precision', 0)
                r = log['metrics'].get('recall', 0)
                log['metrics']['f1'] = self._calculate_f1(p, r)
        
        # ìµœì  ì‹¤í—˜ ì°¾ê¸°
        best = max(logs, key=lambda x: x['metrics'].get(metric, 0))
        
        print("\n" + "="*80)
        print(f"ğŸ† ìµœì  ì„¤ì • ({metric.upper()} ê¸°ì¤€)")
        print("="*80)
        print(f"ì‹¤í—˜ëª…: {best['experiment_name']}")
        print(f"ë‚ ì§œ: {best['timestamp'][:10]}")
        print(f"\nì„¤ì •:")
        for key, value in best['config'].items():
            print(f"  {key}: {value}")
        print(f"\nì„±ëŠ¥:")
        print(f"  Precision: {best['metrics'].get('precision', 0):.4f}")
        print(f"  Recall: {best['metrics'].get('recall', 0):.4f}")
        print(f"  F1: {best['metrics'].get('f1', 0):.4f}")
        print("="*80)
        
        return best
    
    
    # === 5. ìœ í‹¸ë¦¬í‹° ===
    
    def list_experiments(self) -> None:
        """ì €ì¥ëœ ì‹¤í—˜ ëª©ë¡ ì¶œë ¥"""
        logs = self._load_log()
        
        if not logs:
            print("âš ï¸ ì €ì¥ëœ ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        print("\n" + "="*80)
        print("ğŸ“‹ ì €ì¥ëœ ì‹¤í—˜ ëª©ë¡")
        print("="*80)
        
        for i, log in enumerate(logs, 1):
            print(f"\n{i}. {log['experiment_name']}")
            print(f"   ë‚ ì§œ: {log['timestamp'][:10]}")
            print(f"   Precision: {log['metrics'].get('precision', 0):.4f}")
            print(f"   Recall: {log['metrics'].get('recall', 0):.4f}")
        
        print("="*80)
    
    
    def clear_experiments(self) -> None:
        """ëª¨ë“  ì‹¤í—˜ ë¡œê·¸ ì‚­ì œ (ì£¼ì˜!)"""
        confirm = input("âš ï¸ ëª¨ë“  ì‹¤í—˜ ë¡œê·¸ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): ")
        if confirm.lower() == 'yes':
            self._save_log([])
            self._update_summary()
            print("âœ… ëª¨ë“  ì‹¤í—˜ ë¡œê·¸ ì‚­ì œ ì™„ë£Œ")
        else:
            print("âŒ ì·¨ì†Œë¨")
    
    
    # === ë‚´ë¶€ í•¨ìˆ˜ ===
    
    def _load_log(self) -> List[Dict]:
        """ë¡œê·¸ íŒŒì¼ ë¡œë“œ"""
        if not self.log_file.exists():
            return []
        
        with open(self.log_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    
    def _save_log(self, logs: List[Dict]) -> None:
        """ë¡œê·¸ íŒŒì¼ ì €ì¥"""
        with open(self.log_file, 'w', encoding='utf-8') as f:
            json.dump(logs, f, indent=2, ensure_ascii=False)
    
    
    def _update_summary(self) -> None:
        """ìš”ì•½ CSV ì—…ë°ì´íŠ¸"""
        logs = self._load_log()
        
        if not logs:
            return
        
        summary_data = []
        for log in logs:
            row = {
                "timestamp": log['timestamp'],
                "experiment_name": log['experiment_name'],
                "embedding_model": log['config'].get('embedding_model', 'N/A'),
                "top_k": log['config'].get('top_k', 'N/A'),
                "precision": log['metrics'].get('precision', 0),
                "recall": log['metrics'].get('recall', 0),
                "f1": self._calculate_f1(
                    log['metrics'].get('precision', 0),
                    log['metrics'].get('recall', 0)
                ),
                "avg_time": log['metrics'].get('avg_time', 0)
            }
            summary_data.append(row)
        
        df = pd.DataFrame(summary_data)
        df.to_csv(self.summary_file, index=False, encoding='utf-8-sig')
    
    
    @staticmethod
    def _calculate_f1(precision: float, recall: float) -> float:
        """F1 ì ìˆ˜ ê³„ì‚°"""
        if precision + recall == 0:
            return 0
        return 2 * (precision * recall) / (precision + recall)


# ===== ì‚¬ìš© ì˜ˆì‹œ =====

if __name__ == "__main__":
    # Tracker ì´ˆê¸°í™”
    tracker = ExperimentTracker()
    
    # ì˜ˆì‹œ 1: ì‹¤í—˜ ê²°ê³¼ ì €ì¥
    tracker.log_experiment(
        experiment_name="baseline",
        config={
            "embedding_model": "text-embedding-3-small",
            "top_k": 5,
            "chunk_size": 1000
        },
        metrics={
            "precision": 0.30,
            "recall": 0.65,
            "avg_time": 0.41
        },
        notes="ì´ˆê¸° baseline ì‹¤í—˜"
    )
    
    # ì˜ˆì‹œ 2: ì‹¤í—˜ ë¹„êµ
    tracker.compare_experiments()
    
    # ì˜ˆì‹œ 3: ê°œì„  íš¨ê³¼ í™•ì¸
    # tracker.show_improvement("baseline", "embedding-small")
    
    # ì˜ˆì‹œ 4: ì°¨íŠ¸ ìƒì„±
    # tracker.plot_metrics()
    
    # ì˜ˆì‹œ 5: ìµœì  ì„¤ì • ì¶”ì²œ
    # tracker.recommend_best(metric="f1")